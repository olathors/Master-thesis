{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from mri_dataset_combined_3 import MRI_Dataset as MRI_Dataset_combined\n",
    "from mri_dataset import MRI_Dataset\n",
    "from torchvision.models.efficientnet import efficientnet_v2_m, efficientnet_v2_l\n",
    "from combined_classifier import DoubleCombinedClassifierLogReg, CombinedClassifierL, CombinedClassifierLogReg, FourCombinedClassifierLogReg\n",
    "from tqdm import tqdm\n",
    "from evaluation import compute_metrics_binary\n",
    "from roc_curve import RocCurveDisplay\n",
    "from sklearn.metrics import ConfusionMatrixDisplay#, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "import scipy.stats\n",
    "from itertools import cycle\n",
    "from threshold_tuner import ClassificationThresholdTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)\n",
    "plt.style.use('seaborn-v0_8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourclass_val_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCI-pMCI-AD-run_1','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 72, 43])\n",
    "fourclass_test_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 72, 43])\n",
    "\n",
    "fourclass_val_loader = DataLoader(fourclass_val_dataset, batch_size=16, shuffle=True)\n",
    "fourclass_test_loader  = DataLoader(fourclass_test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_threeclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 13, orientation= 'AXIAL')\n",
    "#axial_threeclass_test_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 13, orientation= 'AXIAL')\n",
    "\n",
    "sagittal_threeclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 73, orientation= 'SAGITTAL')\n",
    "#sagittal_threeclass_test_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 73, orientation= 'SAGITTAL')\n",
    "\n",
    "coronal_threeclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 41, orientation= 'CORONAL')\n",
    "#coronal_threeclass_test_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCIpMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 41, orientation= 'CORONAL')\n",
    "\n",
    "axial_threeclass_val_loader = DataLoader(axial_threeclass_val_dataset, batch_size=16, shuffle=True)\n",
    "sagittal_threeclass_val_loader = DataLoader(sagittal_threeclass_val_dataset, batch_size=16, shuffle=True)\n",
    "coronal_threeclass_val_loader = DataLoader(coronal_threeclass_val_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_twoclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-sMCI-pMCI','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 6, orientation='AXIAL')\n",
    "\n",
    "sagittal_twoclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-sMCI-pMCI','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 58, orientation= 'SAGITTAL')\n",
    "\n",
    "coronal_twoclass_val_dataset = MRI_Dataset('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-sMCI-pMCI','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= 43, orientation= 'CORONAL')\n",
    "\n",
    "\n",
    "axial_twoclass_val_loader = DataLoader(axial_twoclass_val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "sagittal_twoclass_val_loader = DataLoader(sagittal_twoclass_val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "coronal_twoclass_val_loader = DataLoader(coronal_twoclass_val_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\naxial = efficientnet_v2_l(num_classes = 4)\\nsagittal = efficientnet_v2_l(num_classes = 4)\\ncoronal = efficientnet_v2_l(num_classes = 4)\\n\\n\\nmodel = CombinedClassifierL(4, axial, sagittal, coronal)\\nmodel.load_state_dict(torch.load('/Users/olath/Downloads/model_4class_202503031601_best.pth', weights_only=True, map_location=torch.device('mps')))\\nmodel.to(device)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "axial = efficientnet_v2_l(num_classes = 4)\n",
    "sagittal = efficientnet_v2_l(num_classes = 4)\n",
    "coronal = efficientnet_v2_l(num_classes = 4)\n",
    "\n",
    "\n",
    "model = CombinedClassifierL(4, axial, sagittal, coronal)\n",
    "model.load_state_dict(torch.load('/Users/olath/Downloads/model_4class_202503031601_best.pth', weights_only=True, map_location=torch.device('mps')))\n",
    "model.to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axial = efficientnet_v2_m(num_classes = 3)\n",
    "axial.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ AXIAL Magnitude_ 12 Ops_ 4 Dropout_ 0.4_202503070702_best.pth', weights_only=True, map_location=torch.device('mps')))\n",
    "sagittal = efficientnet_v2_m(num_classes = 3)\n",
    "sagittal.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ SAGITTAL Magnitude_ 16 Ops_ 4 Dropout_ 0.3_202503071355_best.pth', weights_only=True, map_location=torch.device('mps')))\n",
    "coronal = efficientnet_v2_m(num_classes = 3)\n",
    "coronal.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ CORONAL Magnitude_ 14 Ops_ 3 Dropout_ 0.4_202503070848_best.pth', weights_only=True, map_location=torch.device('mps')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axial = efficientnet_v2_m(num_classes = 2)\n",
    "axial.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ AXIAL Magnitude_ 16 Ops_ 3 Dropout_ 0.2_202503120213_best.pth', weights_only=True, map_location=torch.device('mps')))\n",
    "sagittal = efficientnet_v2_m(num_classes = 2)\n",
    "sagittal.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ SAGITTAL Magnitude_ 16 Ops_ 2 Dropout_ 0.2_202503120244_best.pth', weights_only=True, map_location=torch.device('mps')))\n",
    "coronal = efficientnet_v2_m(num_classes = 2)\n",
    "coronal.load_state_dict(torch.load('/Users/olath/Downloads/model_Orientation_ CORONAL Magnitude_ 14 Ops_ 2 Dropout_ 0.2_202503120101_best.pth', weights_only=True, map_location=torch.device('mps')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists():\n",
    "\n",
    "    global AUC_list; AUC_list = list()\n",
    "    global accuracy_list; accuracy_list = list()\n",
    "    global top2accuracy_list; top2accuracy_list = list()\n",
    "    global f1_list; f1_list = list()\n",
    "    global precision_list; precision_list = list()\n",
    "    global recall_list; recall_list = list()\n",
    "\n",
    "    global auc_CN_list; auc_CN_list = list()\n",
    "    global f1_CN_list; f1_CN_list = list()\n",
    "    global precision_CN_list; precision_CN_list = list()\n",
    "    global recall_CN_list; recall_CN_list = list()\n",
    "\n",
    "    global auc_sMCI_list; auc_sMCI_list = list()\n",
    "    global f1_sMCI_list; f1_sMCI_list = list()\n",
    "    global precision_sMCI_list; precision_sMCI_list = list()\n",
    "    global recall_sMCI_list; recall_sMCI_list = list()\n",
    "\n",
    "    global auc_pMCI_list; auc_pMCI_list = list()\n",
    "    global f1_pMCI_list; f1_pMCI_list = list()\n",
    "    global precision_pMCI_list; precision_pMCI_list = list()\n",
    "    global recall_pMCI_list; recall_pMCI_list = list()\n",
    "\n",
    "    global auc_AD_list; auc_AD_list = list()\n",
    "    global f1_AD_list; f1_AD_list = list()\n",
    "    global precision_AD_list; precision_AD_list = list()\n",
    "    global recall_AD_list; recall_AD_list = list()\n",
    "\n",
    "    global y_true_list; y_true_list = list()\n",
    "    global y_pred_proba_list; y_pred_proba_list = list()\n",
    "\n",
    "    global threshold_list; threshold_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, fourclass_val_loader, fourclass_test_loader):\n",
    "\n",
    "    model = model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predicted_probas = torch.Tensor().to(device)\n",
    "    true_labels = torch.Tensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(fourclass_val_loader, desc=\"Finding best thresholds\"):\n",
    "        # for batch in data_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "\n",
    "            true_labels = torch.cat((true_labels,y),0)\n",
    "            predicted_probas = torch.cat((predicted_probas,y_hat),0)\n",
    "\n",
    "    tuner = ClassificationThresholdTuner()\n",
    "\n",
    "    pred_proba = torch.softmax(predicted_probas, 1).cpu().numpy()\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    best_threshold = tuner.tune_threshold(\n",
    "    y_true=list(map(int, true_labels.cpu().numpy())), \n",
    "    target_classes=['0', '1', '2', '3'],\n",
    "    y_pred_proba=pred_proba,\n",
    "    metric=f1_score,\n",
    "    average='macro',\n",
    "    higher_is_better=True,\n",
    "    max_iterations=500,\n",
    "    default_class='0',\n",
    "    plot_thresholds= True\n",
    ")\n",
    "    print(best_threshold)\n",
    "\n",
    "    predicted_probas = torch.Tensor().to(device)\n",
    "    true_labels = torch.Tensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(fourclass_test_loader, desc=\"Evaluating\"):\n",
    "        # for batch in data_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "\n",
    "            true_labels = torch.cat((true_labels,y),0)\n",
    "            predicted_probas = torch.cat((predicted_probas,y_hat),0)\n",
    "\n",
    "    pred_proba = torch.softmax(predicted_probas, 1).cpu().numpy()\n",
    "\n",
    "    tuned_pred = tuner.get_predictions(\n",
    "    ['0', '1', '2', '3'],\n",
    "    pred_proba, \n",
    "    '0', \n",
    "    best_threshold)\n",
    "    \n",
    "    validation_metrics = compute_metrics_binary(true_labels, predicted_probas, 4, verbose = 0, pred_labels = tuned_pred)\n",
    "\n",
    "    return [validation_metrics, best_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_lists(validation_metrics_list):\n",
    "\n",
    "    validation_metrics = validation_metrics_list[0]\n",
    "\n",
    "    AUC_list.append(validation_metrics['auc'])\n",
    "    accuracy_list.append(validation_metrics['accuracy'])\n",
    "    top2accuracy_list.append(validation_metrics['top_2'])\n",
    "    f1_list.append(validation_metrics['f1score'])\n",
    "    precision_list.append(validation_metrics['precision'])\n",
    "    recall_list.append(validation_metrics['recall'])\n",
    "\n",
    "    auc_CN_list.append(validation_metrics['auc_perclass'][0])\n",
    "    f1_CN_list.append(validation_metrics['f1_perclass'][0])\n",
    "    precision_CN_list.append(validation_metrics['precision_perclass'][0])\n",
    "    recall_CN_list.append(validation_metrics['recall_perclass'][0])\n",
    "\n",
    "    auc_sMCI_list.append(validation_metrics['auc_perclass'][1])\n",
    "    f1_sMCI_list.append(validation_metrics['f1_perclass'][1])\n",
    "    precision_sMCI_list.append(validation_metrics['precision_perclass'][1])\n",
    "    recall_sMCI_list.append(validation_metrics['recall_perclass'][1])\n",
    "\n",
    "    auc_pMCI_list.append(validation_metrics['auc_perclass'][2])\n",
    "    f1_pMCI_list.append(validation_metrics['f1_perclass'][2])\n",
    "    precision_pMCI_list.append(validation_metrics['precision_perclass'][2])\n",
    "    recall_pMCI_list.append(validation_metrics['recall_perclass'][2])\n",
    "\n",
    "    auc_AD_list.append(validation_metrics['auc_perclass'][3])\n",
    "    f1_AD_list.append(validation_metrics['f1_perclass'][3])\n",
    "    precision_AD_list.append(validation_metrics['precision_perclass'][3])\n",
    "    recall_AD_list.append(validation_metrics['recall_perclass'][3])\n",
    "\n",
    "\n",
    "    y_true_list.extend(validation_metrics['roc_auc'][0])\n",
    "    y_pred_proba_list.extend(validation_metrics['roc_auc'][1])\n",
    "\n",
    "    threshold_list.append(validation_metrics_list[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h, np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics():\n",
    "\n",
    "    print(\"Mean AUC:            %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(AUC_list))\n",
    "    print(\"Mean Accuracy:       %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(accuracy_list))\n",
    "    print(\"Mean Top 2 Accuracy: %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(top2accuracy_list))\n",
    "    print(\"Mean F1:             %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(f1_list))\n",
    "    print(\"Mean Precision:      %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(precision_list))\n",
    "    print(\"Mean Recall:         %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(recall_list))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Mean CN AUC:         %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(auc_CN_list))\n",
    "    print(\"Mean CN F1:          %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(f1_CN_list))\n",
    "    print(\"Mean CN Precision:   %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(precision_CN_list))\n",
    "    print(\"Mean CN Recall:      %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(recall_CN_list))\n",
    "    print(\"Mean CN Threshold:   %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval([sublist[0] for sublist in threshold_list]))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Mean sMCI AUC:       %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(auc_sMCI_list))\n",
    "    print(\"Mean sMCI F1:        %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(f1_sMCI_list))\n",
    "    print(\"Mean sMCI Precision: %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(precision_sMCI_list))\n",
    "    print(\"Mean sMCI Recall:    %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(recall_sMCI_list))\n",
    "    print(\"Mean sMCI Threshold: %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval([sublist[1] for sublist in threshold_list]))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Mean pMCI AUC:       %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(auc_pMCI_list))\n",
    "    print(\"Mean pMCI F1:        %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(f1_pMCI_list))\n",
    "    print(\"Mean pMCI Precision: %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(precision_pMCI_list))\n",
    "    print(\"Mean pMCI Recall:    %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(recall_pMCI_list))\n",
    "    print(\"Mean pMCI Threshold: %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval([sublist[2] for sublist in threshold_list]))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Mean AD AUC:         %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(auc_AD_list))\n",
    "    print(\"Mean AD F1:          %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(f1_AD_list))\n",
    "    print(\"Mean AD Precision:   %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(precision_AD_list))\n",
    "    print(\"Mean AD Recall:      %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval(recall_AD_list))\n",
    "    print(\"Mean AD Threshold:   %1.3f ±%1.3f STD: %1.3f\" %mean_confidence_interval([sublist[3] for sublist in threshold_list]))\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_32class(path, num_of_models):\n",
    "\n",
    "    from mri_dataset_combined_2 import MRI_Dataset as MRI_Dataset_combined\n",
    "\n",
    "    create_lists()\n",
    "\n",
    "    fourclass_val_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [13, 73, 41, 6, 58, 43])\n",
    "\n",
    "    fourclass_val_loader  = DataLoader(fourclass_val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    fourclass_test_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [13, 73, 41, 6, 58, 43])\n",
    "\n",
    "    fourclass_test_loader  = DataLoader(fourclass_test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    for i in range(0, num_of_models):\n",
    "\n",
    "        axial1 = efficientnet_v2_m(num_classes = 3)\n",
    "        sagittal1 = efficientnet_v2_m(num_classes = 3)\n",
    "        coronal1 = efficientnet_v2_m(num_classes = 3)\n",
    "        axial2 = efficientnet_v2_m(num_classes = 2)\n",
    "        sagittal2 = efficientnet_v2_m(num_classes = 2)\n",
    "        coronal2 = efficientnet_v2_m(num_classes = 2)\n",
    "\n",
    "        model = DoubleCombinedClassifierLogReg(4, axial1, sagittal1, coronal1, axial2, sagittal2, coronal2, dropout = 0.0, num_outputs = 64)\n",
    "        model.load_state_dict(torch.load(os.path.join(path, (str(i)+'.pth')), weights_only=True, map_location=torch.device('mps')))\n",
    "\n",
    "        add_to_lists(evaluate(model, fourclass_val_loader , fourclass_test_loader))\n",
    "\n",
    "    print_metrics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_4class(path, num_of_models):\n",
    "\n",
    "    from mri_dataset_combined import MRI_Dataset as MRI_Dataset_combined\n",
    "\n",
    "    create_lists()\n",
    "\n",
    "    fourclass_val_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 72, 43])\n",
    "\n",
    "    fourclass_val_loader  = DataLoader(fourclass_val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    fourclass_test_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 72, 43])\n",
    "\n",
    "    fourclass_test_loader  = DataLoader(fourclass_test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    for i in range(0, num_of_models):\n",
    "\n",
    "        axial = efficientnet_v2_l(num_classes = 4)\n",
    "        sagittal = efficientnet_v2_l(num_classes = 4)\n",
    "        coronal = efficientnet_v2_l(num_classes = 4)\n",
    "\n",
    "        model = CombinedClassifierLogReg(4, axial, sagittal, coronal, dropout = 0.0, num_outputs = 32)\n",
    "        model.load_state_dict(torch.load(os.path.join(path, (str(i)+'.pth')), weights_only=True, map_location=torch.device('mps')))\n",
    "\n",
    "        add_to_lists(evaluate(model, fourclass_val_loader, fourclass_test_loader))\n",
    "\n",
    "    print_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_1vrest_class(path, num_of_models):\n",
    "\n",
    "    from mri_dataset_combined_3 import MRI_Dataset as MRI_Dataset_combined\n",
    "\n",
    "    create_lists()\n",
    "\n",
    "    fourclass_val_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/val-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 73, 41, 11, 73, 54, 11, 71, 40, 25, 53, 57])\n",
    "\n",
    "    fourclass_val_loader  = DataLoader(fourclass_val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    fourclass_test_dataset = MRI_Dataset_combined('/Users/olath/Documents/GitHub/Master-thesis/Datasets/test-CN-sMCI-pMCI-AD','/Users/olath/Documents/ADNI_SLICED_RESCALED/', slice= [12, 73, 41, 11, 73, 54, 11, 71, 40, 25, 53, 57])\n",
    "\n",
    "    fourclass_test_loader  = DataLoader(fourclass_test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "    for i in range(0, num_of_models):\n",
    "        \n",
    "        axial1 = efficientnet_v2_m(num_classes = 2)\n",
    "        sagittal1 = efficientnet_v2_m(num_classes = 2)\n",
    "        coronal1 = efficientnet_v2_m(num_classes = 2)\n",
    "        \n",
    "        axial2 = efficientnet_v2_m(num_classes = 2)\n",
    "        sagittal2 = efficientnet_v2_m(num_classes = 2)\n",
    "        coronal2 = efficientnet_v2_m(num_classes = 2)\n",
    "\n",
    "        axial3 = efficientnet_v2_m(num_classes = 2)\n",
    "        sagittal3 = efficientnet_v2_m(num_classes = 2)\n",
    "        coronal3 = efficientnet_v2_m(num_classes = 2)\n",
    "        \n",
    "        axial4 = efficientnet_v2_m(num_classes = 2)\n",
    "        sagittal4 = efficientnet_v2_m(num_classes = 2)\n",
    "        coronal4 = efficientnet_v2_m(num_classes = 2)\n",
    "        \n",
    "        model = FourCombinedClassifierLogReg(4, [(axial1), (sagittal1), (coronal1), (axial2), (sagittal2), (coronal2), (axial3), (sagittal3), (coronal3), (axial4), (sagittal4), (coronal4)], dropout= 0.4, num_outputs = 256)\n",
    "        model.load_state_dict(torch.load(os.path.join(path, (str(i)+'.pth')), weights_only=True, map_location=torch.device('mps')))\n",
    "\n",
    "        add_to_lists(evaluate(model, fourclass_val_loader,fourclass_test_loader))\n",
    "\n",
    "    print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best thresholds: 100%|██████████| 67/67 [00:18<00:00,  3.71it/s]\n",
      "100%|██████████| 500/500 [27:18<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.26, 0.28891591039999986]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:16<00:00,  3.83it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:17<00:00,  3.86it/s]\n",
      "  1%|          | 4/500 [00:15<31:17,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.34555346449999946, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:15<00:00,  4.04it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:16<00:00,  3.99it/s]\n",
      "  3%|▎         | 14/500 [00:48<28:02,  3.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_32class(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/olath/Downloads/32class_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36meval_32class\u001b[0;34m(path, num_of_models)\u001b[0m\n\u001b[1;32m     24\u001b[0m     model \u001b[38;5;241m=\u001b[39m DoubleCombinedClassifierLogReg(\u001b[38;5;241m4\u001b[39m, axial1, sagittal1, coronal1, axial2, sagittal2, coronal2, dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, num_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, (\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)), weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m---> 27\u001b[0m     add_to_lists(evaluate(model, fourclass_val_loader , fourclass_test_loader))\n\u001b[1;32m     29\u001b[0m print_metrics()\n",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, fourclass_val_loader, fourclass_test_loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m     pred_proba \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(predicted_probas, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m---> 26\u001b[0m     best_threshold \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mtune_threshold(\n\u001b[1;32m     27\u001b[0m     y_true\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, true_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())), \n\u001b[1;32m     28\u001b[0m     target_classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     29\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39mpred_proba,\n\u001b[1;32m     30\u001b[0m     metric\u001b[38;5;241m=\u001b[39mf1_score,\n\u001b[1;32m     31\u001b[0m     average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m     higher_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m     max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     34\u001b[0m     default_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(best_threshold)\n\u001b[1;32m     38\u001b[0m     predicted_probas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/GitHub/Master-thesis/Run_Experiments/threshold_tuner.py:947\u001b[0m, in \u001b[0;36mClassificationThresholdTuner.tune_threshold\u001b[0;34m(self, y_true, target_classes, y_pred_proba, metric, higher_is_better, default_class, plot_thresholds, max_iterations, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Loop again for max_iterations times, to set the current threshold given the other thresholds.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iterations):\n\u001b[0;32m--> 947\u001b[0m     are_equal, sorted_array \u001b[38;5;241m=\u001b[39m find_best_threshold_multi(class_idx, min_range, max_range, thresholds)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m are_equal:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Master-thesis/Run_Experiments/threshold_tuner.py:884\u001b[0m, in \u001b[0;36mClassificationThresholdTuner.tune_threshold.<locals>.find_best_threshold_multi\u001b[0;34m(class_idx, min_range, max_range, thresholds)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m test_vals:\n\u001b[1;32m    883\u001b[0m     thresholds[class_idx] \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 884\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_predictions(target_classes, y_pred_proba, default_class, thresholds)\n\u001b[1;32m    885\u001b[0m     score \u001b[38;5;241m=\u001b[39m metric(y_true, pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    886\u001b[0m     scores_arr\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/Documents/GitHub/Master-thesis/Run_Experiments/threshold_tuner.py:987\u001b[0m, in \u001b[0;36mClassificationThresholdTuner.get_predictions\u001b[0;34m(target_classes, y_pred_proba, default_class, thresholds)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(target_classes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (y_pred_proba\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    985\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m y_pred_proba[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 987\u001b[0m d \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred_proba\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target_classes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred_proba\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m    854\u001b[0m         data,\n\u001b[1;32m    855\u001b[0m         columns,\n\u001b[1;32m    856\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    857\u001b[0m         dtype,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:835\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays, columns\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 835\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], abc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    837\u001b[0m     arr, columns \u001b[38;5;241m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:856\u001b[0m, in \u001b[0;36m_list_to_arrays\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    853\u001b[0m     content \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mto_object_array_tuples(data)\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# list of lists\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     content \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mto_object_array(data)\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_32class('/Users/olath/Downloads/32class_weights', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.43it/s]\n",
      "  4%|▍         | 2/50 [00:02<01:09,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.29840000000000005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.46it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.32it/s]\n",
      "  6%|▌         | 3/50 [00:03<00:58,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.29136, 0.2, 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:14<00:00,  4.40it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.43it/s]\n",
      "  4%|▍         | 2/50 [00:04<01:56,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.2920000000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.44it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.46it/s]\n",
      " 10%|█         | 5/50 [00:10<01:33,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.29919000000000007, 0.2, 0.2993014560000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.48it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.30it/s]\n",
      "  4%|▍         | 2/50 [00:02<01:11,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.2968000000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.47it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:16<00:00,  4.17it/s]\n",
      "  4%|▍         | 2/50 [00:05<02:04,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.29790000000000016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.46it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.45it/s]\n",
      "  4%|▍         | 2/50 [00:01<00:27,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:14<00:00,  4.42it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:14<00:00,  4.48it/s]\n",
      "  4%|▍         | 2/50 [00:01<00:24,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:13<00:00,  4.46it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.44it/s]\n",
      "  4%|▍         | 2/50 [00:01<00:27,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:14<00:00,  4.41it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:15<00:00,  4.35it/s]\n",
      "  4%|▍         | 2/50 [00:01<00:28,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2, 0.2, 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:14<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC:            0.712 ±0.002 STD: 0.002\n",
      "Mean Accuracy:       0.430 ±0.005 STD: 0.007\n",
      "Mean Top 2 Accuracy: 0.736 ±0.007 STD: 0.009\n",
      "Mean F1:             0.416 ±0.005 STD: 0.006\n",
      "Mean Precision:      0.437 ±0.006 STD: 0.008\n",
      "Mean Recall:         0.416 ±0.006 STD: 0.008\n",
      "---------------------------------\n",
      "Mean CN AUC:         0.736 ±0.004 STD: 0.005\n",
      "Mean CN F1:          0.524 ±0.010 STD: 0.013\n",
      "Mean CN Precision:   0.463 ±0.013 STD: 0.017\n",
      "Mean CN Recall:      0.607 ±0.030 STD: 0.040\n",
      "Mean CN Threshold:   0.000 ±0.000 STD: 0.000\n",
      "---------------------------------\n",
      "Mean sMCI AUC:       0.614 ±0.004 STD: 0.006\n",
      "Mean sMCI F1:        0.362 ±0.022 STD: 0.029\n",
      "Mean sMCI Precision: 0.397 ±0.013 STD: 0.017\n",
      "Mean sMCI Recall:    0.339 ±0.040 STD: 0.052\n",
      "Mean sMCI Threshold: 0.219 ±0.029 STD: 0.038\n",
      "---------------------------------\n",
      "Mean pMCI AUC:       0.696 ±0.004 STD: 0.005\n",
      "Mean pMCI F1:        0.321 ±0.026 STD: 0.034\n",
      "Mean pMCI Precision: 0.313 ±0.010 STD: 0.013\n",
      "Mean pMCI Recall:    0.335 ±0.047 STD: 0.062\n",
      "Mean pMCI Threshold: 0.200 ±0.000 STD: 0.000\n",
      "---------------------------------\n",
      "Mean AD AUC:         0.800 ±0.004 STD: 0.005\n",
      "Mean AD F1:          0.458 ±0.015 STD: 0.020\n",
      "Mean AD Precision:   0.575 ±0.024 STD: 0.031\n",
      "Mean AD Recall:      0.384 ±0.028 STD: 0.037\n",
      "Mean AD Threshold:   0.288 ±0.022 STD: 0.030\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_4class('/Users/olath/Downloads/4class_weights', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best thresholds: 100%|██████████| 67/67 [00:35<00:00,  1.89it/s]\n",
      "  4%|▍         | 2/50 [00:05<02:10,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2996000000000001, 0.2, 0.29992]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.90it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:35<00:00,  1.88it/s]\n",
      " 12%|█▏        | 6/50 [00:11<01:24,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.299937, 0.2, 0.29234826752000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.92it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:34<00:00,  1.92it/s]\n",
      "  4%|▍         | 2/50 [00:07<03:09,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.30000000000000004, 0.2, 0.29960000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.89it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [01:04<00:00,  1.04it/s]\n",
      "  8%|▊         | 4/50 [00:11<02:16,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.29813028599999997, 0.2, 0.2994400000000001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:33<00:00,  1.87it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:35<00:00,  1.90it/s]\n",
      "  6%|▌         | 3/50 [00:10<02:38,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.30000000000000004, 0.2, 0.299937]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:34<00:00,  1.79it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:35<00:00,  1.87it/s]\n",
      "  8%|▊         | 4/50 [00:10<01:58,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2961000000000001, 0.2, 0.29813721600000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.91it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:43<00:00,  1.55it/s]\n",
      "  6%|▌         | 3/50 [00:08<02:18,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.294336, 0.2, 0.29719999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:33<00:00,  1.86it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:36<00:00,  1.85it/s]\n",
      "  4%|▍         | 2/50 [00:09<03:50,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2960000000000001, 0.2, 0.29760000000000014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:33<00:00,  1.84it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:34<00:00,  1.93it/s]\n",
      "  6%|▌         | 3/50 [00:04<01:10,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.2982180000000001, 0.2, 0.30000000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.94it/s]\n",
      "Finding best thresholds: 100%|██████████| 67/67 [00:35<00:00,  1.91it/s]\n",
      "  8%|▊         | 4/50 [00:08<01:38,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.29933499999999996, 0.2, 0.294158577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:32<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC:            0.735 ±0.002 STD: 0.002\n",
      "Mean Accuracy:       0.444 ±0.007 STD: 0.009\n",
      "Mean Top 2 Accuracy: 0.755 ±0.006 STD: 0.007\n",
      "Mean F1:             0.413 ±0.011 STD: 0.015\n",
      "Mean Precision:      0.486 ±0.007 STD: 0.009\n",
      "Mean Recall:         0.408 ±0.009 STD: 0.012\n",
      "---------------------------------\n",
      "Mean CN AUC:         0.762 ±0.001 STD: 0.002\n",
      "Mean CN F1:          0.521 ±0.006 STD: 0.007\n",
      "Mean CN Precision:   0.485 ±0.007 STD: 0.009\n",
      "Mean CN Recall:      0.563 ±0.016 STD: 0.021\n",
      "Mean CN Threshold:   0.000 ±0.000 STD: 0.000\n",
      "---------------------------------\n",
      "Mean sMCI AUC:       0.634 ±0.005 STD: 0.007\n",
      "Mean sMCI F1:        0.450 ±0.008 STD: 0.011\n",
      "Mean sMCI Precision: 0.372 ±0.006 STD: 0.008\n",
      "Mean sMCI Recall:    0.570 ±0.017 STD: 0.023\n",
      "Mean sMCI Threshold: 0.298 ±0.001 STD: 0.002\n",
      "---------------------------------\n",
      "Mean pMCI AUC:       0.728 ±0.002 STD: 0.002\n",
      "Mean pMCI F1:        0.293 ±0.010 STD: 0.013\n",
      "Mean pMCI Precision: 0.494 ±0.019 STD: 0.025\n",
      "Mean pMCI Recall:    0.209 ±0.012 STD: 0.016\n",
      "Mean pMCI Threshold: 0.200 ±0.000 STD: 0.000\n",
      "---------------------------------\n",
      "Mean AD AUC:         0.816 ±0.002 STD: 0.002\n",
      "Mean AD F1:          0.389 ±0.033 STD: 0.044\n",
      "Mean AD Precision:   0.593 ±0.007 STD: 0.009\n",
      "Mean AD Recall:      0.292 ±0.036 STD: 0.048\n",
      "Mean AD Threshold:   0.298 ±0.002 STD: 0.003\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_1vrest_class('/Users/olath/Downloads/1vrest_weights', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'axial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m axial\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'axial' is not defined"
     ]
    }
   ],
   "source": [
    "model = axial\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predicted_probas = torch.Tensor().to(device)\n",
    "true_labels = torch.Tensor().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(axial_twoclass_val_loader, desc=\"Evaluating\"):\n",
    "    # for batch in data_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "\n",
    "        true_labels = torch.cat((true_labels,y),0)\n",
    "        predicted_probas = torch.cat((predicted_probas,y_hat),0)\n",
    "\n",
    "validation_metrics1 = compute_metrics_binary(true_labels, predicted_probas, 2, verbose = 1)\n",
    "\n",
    "model = sagittal\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predicted_probas = torch.Tensor().to(device)\n",
    "true_labels = torch.Tensor().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(sagittal_twoclass_val_loader, desc=\"Evaluating\"):\n",
    "    # for batch in data_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "\n",
    "        true_labels = torch.cat((true_labels,y),0)\n",
    "        predicted_probas = torch.cat((predicted_probas,y_hat),0)\n",
    "\n",
    "validation_metrics2 = compute_metrics_binary(true_labels, predicted_probas, 2, verbose = 1)\n",
    "\n",
    "model = coronal\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predicted_probas = torch.Tensor().to(device)\n",
    "true_labels = torch.Tensor().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(coronal_twoclass_val_loader, desc=\"Evaluating\"):\n",
    "    # for batch in data_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "\n",
    "        true_labels = torch.cat((true_labels,y),0)\n",
    "        predicted_probas = torch.cat((predicted_probas,y_hat),0)\n",
    "\n",
    "validation_metrics3 = compute_metrics_binary(true_labels, predicted_probas, 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m confusiom_matrix \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(validation_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf_mat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m confusiom_matrix\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "confusiom_matrix = ConfusionMatrixDisplay(validation_metrics['conf_mat'])\n",
    "confusiom_matrix.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_multiclass_curve(y_true, y_score, n_classes, target_names, name, fig, ax):\n",
    "    #This function is from sklearn website.\n",
    "\n",
    "    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    y_onehot_test = label_binarizer.fit_transform(y_true)   \n",
    "\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "    # Interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = fpr_grid\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \"\"\"\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.3f})\",\n",
    "        #color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "    \"\"\"\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=name+f\" (AUC = {roc_auc['macro']:.3f})\",\n",
    "        #color=\"navy\",\n",
    "        #linestyle=\":\",\n",
    "        #linewidth=4,\n",
    "    )\n",
    "    \"\"\"\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"navy\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "            plot_chance_level=(class_id == 1),\n",
    "            #despine=True,\n",
    "        )\n",
    "    \n",
    "    _ = ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest Multiclass\",\n",
    "    )\n",
    "    \"\"\"\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_curve(y_true, y_score, n_classes, target_names, name, values):\n",
    "    #This function is from sklearn website.\n",
    "\n",
    "    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    y_onehot_test = label_binarizer.fit_transform(y_true)   \n",
    "\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "    # Interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = fpr_grid\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \"\"\"\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.3f})\",\n",
    "        #color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=f\"macro-average ROC curve (AUC = {values[4]:.3f})\",\n",
    "        #color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"navy\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            #color=color,\n",
    "            ax=ax,\n",
    "            list = values[class_id],\n",
    "            #plot_chance_level=(class_id == 1),\n",
    "            #despine=True,\n",
    "        )\n",
    "\n",
    "    _ = ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"One-vs-Rest Multiclass ROC Curves for \" + name + \".\",\n",
    "    )\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiclass_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#fig, ax = plt.subplots(figsize=(6, 6))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#y_true, y_pred_proba, threshold = validation_metrics['roc_auc']\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m multiclass_curve(np\u001b[38;5;241m.\u001b[39marray(y_true_list), np\u001b[38;5;241m.\u001b[39marray(y_pred_proba_list), \u001b[38;5;241m4\u001b[39m, {\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCN\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msMCI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpMCI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAD\u001b[39m\u001b[38;5;124m'\u001b[39m}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne-vs-Rest Ensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m, values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.762\u001b[39m,\u001b[38;5;241m0.634\u001b[39m,\u001b[38;5;241m0.728\u001b[39m,\u001b[38;5;241m0.816\u001b[39m,\u001b[38;5;241m0.735\u001b[39m])\n\u001b[1;32m      6\u001b[0m ax\u001b[38;5;241m.\u001b[39mmargins(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      7\u001b[0m default_chance_level_line_kw \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChance level (AUC = 0.5)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinestyle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multiclass_curve' is not defined"
     ]
    }
   ],
   "source": [
    "#fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "#y_true, y_pred_proba, threshold = validation_metrics['roc_auc']\n",
    "\n",
    "fig, ax = multiclass_curve(np.array(y_true_list), np.array(y_pred_proba_list), 4, {0:'CN',1:'sMCI', 2:'pMCI', 3:'AD'}, \"One-vs-Rest Ensemble\", values = [0.762,0.634,0.728,0.816,0.735])\n",
    "ax.margins(x=0.01, y = 0.01)\n",
    "default_chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "ax.plot((0, 1), (0, 1), **default_chance_level_line_kw)\n",
    "plt.legend(loc=0)\n",
    "#plt.show()\n",
    "plt.savefig('/Users/olath/Documents/ensemble-1vRest-roclpot(testdata).pdf', dpi = 1200, bbox_inches='tight')\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "y_true1, y_pred_proba1, threshold = validation_metrics1['roc_auc']\n",
    "\n",
    "y_true2, y_pred_proba2, threshold = validation_metrics2['roc_auc']\n",
    "\n",
    "y_true3, y_pred_proba3, threshold = validation_metrics3['roc_auc']\n",
    "\n",
    "fig, ax = custom_multiclass_curve(y_true1, y_pred_proba1, 3, {0:'CN', 1:'MCI', 2:'AD'}, \"Axial\", fig, ax)\n",
    "\n",
    "fig, ax = custom_multiclass_curve(y_true2, y_pred_proba2, 3, {0:'CN', 1:'MCI', 2:'AD'}, \"Sagittal\", fig, ax)\n",
    "\n",
    "fig, ax = custom_multiclass_curve(y_true3, y_pred_proba3, 3, {0:'CN', 1:'MCI', 2:'AD'}, \"Coronal\", fig, ax)\n",
    "\n",
    "default_chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "ax.plot((0, 1), (0, 1), **default_chance_level_line_kw)\n",
    "ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"Macro Average ROC Curves for CN/MCI/AD Submodels\",\n",
    "    )\n",
    "ax.margins(x=0.01, y = 0.01)\n",
    "plt.legend(loc=0)\n",
    "#plt.show()\n",
    "plt.savefig('/Users/olath/Documents/cn-mci-ad-roclpot(valdata).pdf', dpi = 1200, bbox_inches='tight')\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "label = validation_metrics1['roc_auc'][0]\n",
    "pred = validation_metrics1['roc_auc'][1]\n",
    "fpr, tpr, thresh = roc_curve(label, pred[:, 1])\n",
    "auc = roc_auc_score(label, pred[:, 1])\n",
    "plt.plot(fpr,tpr,label=\"Axial\"+f\" (AUC = {auc:.3f})\")\n",
    "\n",
    "label = validation_metrics2['roc_auc'][0]\n",
    "pred = validation_metrics2['roc_auc'][1]\n",
    "fpr, tpr, thresh = roc_curve(label, pred[:, 1])\n",
    "auc = roc_auc_score(label, pred[:, 1])\n",
    "plt.plot(fpr,tpr,label=\"Sagittal\"+f\" (AUC = {auc:.3f})\")\n",
    "\n",
    "label = validation_metrics3['roc_auc'][0]\n",
    "pred = validation_metrics3['roc_auc'][1]\n",
    "fpr, tpr, thresh = roc_curve(label, pred[:, 1])\n",
    "auc = roc_auc_score(label, pred[:, 1])\n",
    "plt.plot(fpr,tpr,label=\"Coronal\"+f\" (AUC = {auc:.3f})\")\n",
    "\n",
    "default_chance_level_line_kw = {\n",
    "            \"label\": \"Chance level (AUC = 0.5)\",\n",
    "            \"color\": \"k\",\n",
    "            \"linestyle\": \"--\",\n",
    "        }\n",
    "ax.plot((0, 1), (0, 1), **default_chance_level_line_kw)\n",
    "ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"ROC Curves for sMCI/pMCI Submodels\",\n",
    "    )\n",
    "ax.margins(x=0.01, y = 0.01)\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.savefig('/Users/olath/Documents/smci-pmci-roclpot(valdata).pdf', dpi = 1200, bbox_inches='tight')\n",
    "plt.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
